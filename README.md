# Chain-of-Thought Prompting

This paper discusses a trick for "making large models think better at low cost": when asking questions, donâ€™t just request the answer; instead, include a few examples with detailed solution steps in the prompt. The author calls this approach "Chain-of-Thought prompting," abbreviated as CoT. With these demonstrations, the model is more likely to follow a 'think step by step before answering' approach on new problems, often significantly improving accuracy on complex questions. The reason this method works is that the chain of thought breaks down a difficult problem that would normally be taken in one big bite into smaller steps: first extracting conditions, then setting intermediate variables, and gradually performing calculations or eliminations. For large models, this structured process signal is easier to learn and reuse than "directly supplying the final answer." The paper also conducted many control experiments to rule out the misconception that "writing more words makes it more accurate": merely asking the model to first write an equation, or to first output some meaningless placeholders, or even to give the answer first and then fill in the process, is not as effective as genuinely writing out the reasoning step by step in natural language. The key is "step-by-step reasoning," not word count. In tasks such as elementary school word problems, commonsense reasoning, and symbolic reasoning, prompts with chain-of-thought generally outperform standard prompts; the more multi-step reasoning a task requires, the greater the benefit; for simple problems that can be solved in one step, the improvement is minimal or even nonexistent. The paper also identifies a "scale threshold": small models, even when given chain-of-thought examples, often produce sentences that are fluent but logically incorrect; only when the model reaches a scale of tens of billions of parameters does the advantage of chain-of-thought truly "emerge," with a substantial increase in accuracy.The paper also reports a phenomenon of "length extrapolation.
